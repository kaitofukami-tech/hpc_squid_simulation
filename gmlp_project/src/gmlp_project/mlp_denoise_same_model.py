#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
MLP Denoising (Same Init)
- Based on mlp_same_model.py
- Task: Denoising (MSE Loss, Input=Noisy, Target=Clean)
- Dataset: generated by build_denoise_datasets.py
- Strategy: Same Initialization, Different Shuffle
"""

import os, math, time, json, argparse, logging, hashlib, tempfile, shutil, gc, csv
from typing import List, Dict, Tuple
import numpy as np
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, TensorDataset

# ----------------- argparse -----------------
def build_args():
    p = argparse.ArgumentParser("MLP Denoising (same init)")
    p.add_argument("--input", type=str, required=True,
                   help="Denoising .npz file (e.g. mnist_lambda100.npz)")
    p.add_argument("--output_dir", type=str, default="/sqfs/work/cm9029/${USER_ID}/mlp_output/denoise_same")
    p.add_argument("--epochs", type=int, default=15)
    p.add_argument("--batch_size", type=int, default=256)
    p.add_argument("--lr", type=float, default=1e-3)

    # MLP dims
    p.add_argument("--d_model", type=int, default=256)
    p.add_argument("--d_ffn", type=int, default=1024)
    p.add_argument("--num_blocks", type=int, default=10)
    p.add_argument("--dropout", type=float, default=0.1)

    # Training/Measurement
    p.add_argument("--init_seed", type=int, default=123, help="Shared Init seed for A/B")
    p.add_argument("--train_seedA", type=int, default=2025, help="Shuffle seed for A")
    p.add_argument("--train_seedB", type=int, default=4242, help="Shuffle seed for B")
    p.add_argument("--data_seed", type=int, default=4244, help="Measurement sample selection seed")
    p.add_argument("--M", type=int, default=1000, help="Number of spin measurement samples")
    p.add_argument("--record_layers", type=str, default=":post", choices=[":pre",":post"])
    p.add_argument("--measure_data", type=str, default="train", choices=["train", "val"])
    p.add_argument("--no-epoch0", action="store_true", default=True)
    p.add_argument("--log_level", type=str, default="INFO", choices=["DEBUG","INFO","WARNING","ERROR"])

    # Progressive recording params
    p.add_argument("--record-start", type=int, default=2)
    p.add_argument("--record-mult", type=float, default=1.5)
    p.add_argument("--record-max", type=int, default=50)
    p.add_argument("--always-include-last", action="store_true", default=True)

    return p.parse_args()

# ----------------- logging -----------------
def setup_logger(outdir, level="INFO"):
    os.makedirs(outdir, exist_ok=True)
    logger = logging.getLogger("MLP_Denoise_Same")
    logger.setLevel(getattr(logging, level))
    fmt = logging.Formatter("%(asctime)s - %(levelname)s - %(message)s")
    sh = logging.StreamHandler(); sh.setFormatter(fmt)
    fh = logging.FileHandler(os.path.join(outdir, "train.log")); fh.setFormatter(fmt)
    logger.handlers.clear(); logger.addHandler(sh); logger.addHandler(fh)
    return logger

# ----------------- utils -----------------
def dev():
    return torch.device("cuda" if torch.cuda.is_available() else "cpu")

def set_seed_all(seed:int):
    torch.manual_seed(seed); np.random.seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)
        torch.backends.cudnn.deterministic = True
        torch.backends.cudnn.benchmark = False

def prep_tensor(arr):
    t = torch.tensor(arr, dtype=torch.float32)
    if t.max() > 1.0 + 1e-6:
        t = t / 255.0
    if t.ndim == 3: t = t.unsqueeze(1)
    elif t.ndim == 2: t = t.view(t.size(0), 1, 28, 28)
    return t

def load_denoise_data(path, logger):
    logger.info(f"Loading {path} ...")
    with np.load(path) as f:
        nt = f["noisy_train"]
        ct = f["clean_train"]
        nv = f["noisy_test"]
        cv = f["clean_test"]
    nt_t = prep_tensor(nt)
    ct_t = prep_tensor(ct)
    nv_t = prep_tensor(nv)
    cv_t = prep_tensor(cv)
    train_ds = TensorDataset(nt_t, ct_t)
    val_ds   = TensorDataset(nv_t, cv_t)
    return train_ds, val_ds

def make_loader(dataset, bs, seed, logger, *, shuffle=True):
    g = torch.Generator()
    g.manual_seed(seed)
    dl = DataLoader(dataset, batch_size=bs, shuffle=shuffle, num_workers=2, pin_memory=True, generator=g if shuffle else None)
    if shuffle:
        logger.info(f"steps/epoch â‰ˆ {math.ceil(len(dataset)/bs)}")
    return dl

def atomic_save_pickle(obj, final_path, logger):
    os.makedirs(os.path.dirname(final_path), exist_ok=True)
    tmpdir = os.getenv("SLURM_TMPDIR", "/tmp")
    with tempfile.NamedTemporaryFile(dir=tmpdir, delete=False, suffix=".pkl") as tmp:
        import pickle
        pickle.dump(obj, tmp, protocol=pickle.HIGHEST_PROTOCOL)
        tmp.flush(); os.fsync(tmp.fileno())
        tmp_path = tmp.name
    shutil.move(tmp_path, final_path)
    sz = os.path.getsize(final_path)/(1024**2)
    logger.info(f"Saved: {final_path} ({sz:.2f} MB)")

def atomic_save_state_dict(model: nn.Module, final_path: str, logger):
    os.makedirs(os.path.dirname(final_path), exist_ok=True)
    tmpdir = os.getenv("SLURM_TMPDIR", "/tmp")
    with tempfile.NamedTemporaryFile(dir=tmpdir, delete=False, suffix=".pt") as tmp:
        torch.save(model.state_dict(), tmp)
        tmp.flush(); os.fsync(tmp.fileno())
        tmp_path = tmp.name
    shutil.move(tmp_path, final_path)
    sz = os.path.getsize(final_path)/(1024**2)
    logger.info(f"Saved checkpoint: {final_path} ({sz:.2f} MB)")

def save_metrics_csv(path, rows, logger):
    os.makedirs(os.path.dirname(path), exist_ok=True)
    with open(path, "w", newline="") as f:
        writer = csv.DictWriter(f, fieldnames=["epoch","split","loss"])
        writer.writeheader()
        for r in rows: writer.writerow(r)
    logger.info(f"Saved metrics CSV: {path}")

def model_state_hash(model):
    with torch.no_grad():
        vec = torch.cat([p.detach().float().flatten().cpu() for p in model.parameters()])
    return hashlib.sha256(vec.numpy().tobytes()).hexdigest()

# ----------------- MLP -----------------
class MLPBlock(nn.Module):
    def __init__(self, d_model, d_ffn, dropout=0.1):
        super().__init__()
        self.bn = nn.BatchNorm1d(d_model)
        self.fc1 = nn.Linear(d_model, d_ffn)
        self.act = nn.GELU()
        self.fc2 = nn.Linear(d_ffn, d_model)
        self.drop = nn.Dropout(dropout)
    def forward(self, x):
        residual = x
        x = self.bn(x)
        x = self.fc1(x)
        x = self.act(x)
        x = self.fc2(x)
        x = self.drop(x)
        return x + residual

class MLP(nn.Module):
    def __init__(self, input_dim=784, d_model=256, d_ffn=1024,
                 num_blocks=10, output_dim=784, dropout=0.1):
        super().__init__()
        self.input_proj = nn.Linear(input_dim, d_model)
        self.blocks = nn.ModuleList([MLPBlock(d_model, d_ffn, dropout) for _ in range(num_blocks)])
        self.out_bn = nn.BatchNorm1d(d_model)
        self.output_proj = nn.Linear(d_model, output_dim)
    def forward(self, x_img):
        B = x_img.size(0)
        x = x_img.view(B, -1)
        x = self.input_proj(x)
        for blk in self.blocks: x = blk(x)
        x = self.out_bn(x)
        return self.output_proj(x)

def init_random_normal_and_bias_const(model: nn.Module, *, mean=0.0, std=1.0, bias_const=0.1):
    for m in model.modules():
        if isinstance(m, (nn.Linear, nn.Conv1d)):
            if m.weight is not None: nn.init.normal_(m.weight, mean=mean, std=std)
            if m.bias is not None: nn.init.constant_(m.bias, bias_const)

# ----------------- spin recording -----------------
@torch.no_grad()
def measure_spins(model: nn.Module, layer_names: List[str], X_meas: torch.Tensor, batch: int, logger):
    model.eval()
    store = {ln: [] for ln in layer_names}
    name_map = {}
    for ln in layer_names:
        base = ln.replace(':pre','').replace(':post','')
        is_pre = ln.endswith(':pre')
        name_map.setdefault(base, []).append((ln, is_pre))

    handles = []
    for n, m in model.named_modules():
        if n in name_map:
            for out_key, is_pre in name_map[n]:
                if is_pre:
                    def _pre_hook_factory(key):
                        def _pre(_m, inputs):
                            store[key].append(inputs[0].detach().to("cpu", dtype=torch.float16))
                        return _pre
                    handles.append(m.register_forward_pre_hook(_pre_hook_factory(out_key)))
                else:
                    def _hook_factory(key):
                        def _hook(_m, _in, out):
                            store[key].append(out.detach().to("cpu", dtype=torch.float16))
                        return _hook
                    handles.append(m.register_forward_hook(_hook_factory(out_key)))

    dl = DataLoader(TensorDataset(X_meas), batch_size=batch, shuffle=False, num_workers=2, pin_memory=True)
    d = dev()
    for (xb,) in dl:
        _ = model(xb.to(d, non_blocking=True))
    for h in handles: h.remove()
    for k in store.keys():
        store[k] = torch.cat(store[k], dim=0)
        logger.info(f"[spin] {k}: {tuple(store[k].shape)}")
    if torch.cuda.is_available(): torch.cuda.empty_cache()
    return store

def build_epochs_1_3_then_progressive(total_epochs: int, start: int, mult: float, max_interval: int, include_last: bool) -> List[int]:
    fixed = [e for e in (1, 3) if 1 <= e <= total_epochs]
    epochs = list(sorted(set(fixed)))
    cur = 3 if 3 <= total_epochs else (1 if 1 <= total_epochs else 0)
    interval = max(1, start)
    i = 0
    while True:
        cur = cur + interval
        if cur > total_epochs: break
        if cur not in epochs: epochs.append(cur)
        interval = min(max_interval, max(1, int(round(interval * mult))))
        i += 1
        if i > 10000: break
    if include_last and total_epochs >= 1 and total_epochs not in epochs: epochs.append(total_epochs)
    return sorted(set([e for e in epochs if 1 <= e <= total_epochs]))

def train_one_epoch(model, loader, opt, loss_fn, logger, tag):
    model.train(); d = dev()
    total_loss, n = 0.0, 0
    for xb, yb in loader:
        xb, yb = xb.to(d, non_blocking=True), yb.to(d, non_blocking=True)
        yb_flat = yb.view(yb.size(0), -1)
        opt.zero_grad(set_to_none=True)
        out = model(xb)
        loss = loss_fn(out, yb_flat)
        loss.backward()
        opt.step()
        total_loss += float(loss) * xb.size(0)
        n += xb.size(0)
    avg_loss = total_loss / max(n, 1)
    logger.info(f"[{tag}] train_loss={avg_loss:.6f}")
    return avg_loss

@torch.no_grad()
def eval_full(model, loader, loss_fn):
    model.eval(); d = dev()
    total_loss, n = 0.0, 0
    for xb, yb in loader:
        xb, yb = xb.to(d, non_blocking=True), yb.to(d, non_blocking=True)
        yb_flat = yb.view(yb.size(0), -1)
        out = model(xb)
        loss = loss_fn(out, yb_flat)
        total_loss += float(loss) * xb.size(0)
        n += xb.size(0)
    return total_loss / max(n, 1)

def main():
    args = build_args()
    ts = time.strftime("%Y%m%d-%H%M%S")
    input_stem = os.path.splitext(os.path.basename(args.input))[0]
    run_name = f"run_same_{input_stem}_{args.measure_data}_{ts}"
    outdir = os.path.join(args.output_dir, run_name)
    logger = setup_logger(outdir, args.log_level)
    logger.info(f"Args: {json.dumps(vars(args), ensure_ascii=False)}")
    
    train_ds, val_ds = load_denoise_data(args.input, logger)
    if args.measure_data == "train":
        source_data = train_ds.tensors[0]
        logger.info(f"Measure Target: TRAIN (N={len(source_data)})")
    else:
        source_data = val_ds.tensors[0]
        logger.info(f"Measure Target: VAL/TEST (N={len(source_data)})")
    
    rng = np.random.RandomState(args.data_seed)
    N_total = len(source_data)
    if N_total < args.M:
        idx_meas = np.arange(N_total)
    else:
        idx_meas = rng.choice(N_total, size=args.M, replace=False)
    X_meas = source_data[idx_meas].clone()
    
    loaderA = make_loader(train_ds, args.batch_size, seed=args.train_seedA, logger=logger, shuffle=True)
    loaderB = make_loader(train_ds, args.batch_size, seed=args.train_seedB, logger=logger, shuffle=True)
    train_eval_loader = make_loader(train_ds, args.batch_size, seed=0, logger=logger, shuffle=False)
    val_loader        = make_loader(val_ds,   args.batch_size, seed=0, logger=logger, shuffle=False)
    
    layer_list = [f"blocks.{i}.bn{args.record_layers}" for i in range(args.num_blocks)]
    rec_epochs = build_epochs_1_3_then_progressive(args.epochs, args.record_start, args.record_mult, args.record_max, args.always_include_last)
    loss_fn = nn.MSELoss()
    d = dev()
    
    set_seed_all(args.init_seed)
    modelA = MLP(d_model=args.d_model, d_ffn=args.d_ffn, num_blocks=args.num_blocks, output_dim=784, dropout=args.dropout).to(d)
    init_random_normal_and_bias_const(modelA)
    hashA = model_state_hash(modelA)
    
    modelB = MLP(d_model=args.d_model, d_ffn=args.d_ffn, num_blocks=args.num_blocks, output_dim=784, dropout=args.dropout).to(d)
    modelB.load_state_dict(modelA.state_dict())
    hashB = model_state_hash(modelB)
    logger.info(f"Init Hash: A={hashA[:8]}, B={hashB[:8]} (Match={hashA==hashB})")
    
    spinsA = {ln: [] for ln in layer_list}; timeA = []
    spinsB = {ln: [] for ln in layer_list}; timeB = []
    metrics_A = []; metrics_B = []
    ckpt_root = os.path.join(args.output_dir, "checkpoints", run_name)
    ckpt_dir_A = os.path.join(ckpt_root, "A")
    ckpt_dir_B = os.path.join(ckpt_root, "B")
    ckpt_A = []; ckpt_B = []
    
    if not args.no_epoch0:
        s = measure_spins(modelA, layer_list, X_meas, min(256, len(X_meas)), logger)
        for k in layer_list: spinsA[k].append(s[k])
        timeA.append(0)
        s = measure_spins(modelB, layer_list, X_meas, min(256, len(X_meas)), logger)
        for k in layer_list: spinsB[k].append(s[k])
        timeB.append(0)
    
    optA = torch.optim.Adam(modelA.parameters(), lr=args.lr)
    optB = torch.optim.Adam(modelB.parameters(), lr=args.lr)
    
    for ep in range(1, args.epochs+1):
        train_one_epoch(modelA, loaderA, optA, loss_fn, logger, f"A/ep{ep}")
        train_one_epoch(modelB, loaderB, optB, loss_fn, logger, f"B/ep{ep}")
        
        if ep in rec_epochs:
            s = measure_spins(modelA, layer_list, X_meas, min(256, len(X_meas)), logger)
            for k in layer_list: spinsA[k].append(s[k])
            timeA.append(ep)
            s = measure_spins(modelB, layer_list, X_meas, min(256, len(X_meas)), logger)
            for k in layer_list: spinsB[k].append(s[k])
            timeB.append(ep)
            
            la_tr = eval_full(modelA, train_eval_loader, loss_fn)
            la_va = eval_full(modelA, val_loader, loss_fn)
            metrics_A.extend([{"epoch":ep,"split":"train","loss":f"{la_tr:.6f}"}, {"epoch":ep,"split":"val","loss":f"{la_va:.6f}"}])
            
            lb_tr = eval_full(modelB, train_eval_loader, loss_fn)
            lb_va = eval_full(modelB, val_loader, loss_fn)
            metrics_B.extend([{"epoch":ep,"split":"train","loss":f"{lb_tr:.6f}"}, {"epoch":ep,"split":"val","loss":f"{lb_va:.6f}"}])
            logger.info(f"Eval[{ep}] A: tr={la_tr:.5f} val={la_va:.5f} | B: tr={lb_tr:.5f} val={lb_va:.5f}")
            gc.collect()

    meta = dict(data_name=input_stem, d_model=args.d_model, d_ffn=args.d_ffn, num_blocks=args.num_blocks, 
                dropout=args.dropout, record_layers=args.record_layers, M=args.M, 
                measure_data=args.measure_data, arch="MLP_Denoise_Same")
    
    dumpA = {"meta": {**meta, "tag":"A", "init_seed":args.init_seed, "train_seed":args.train_seedA, "time":timeA, "record_epochs":rec_epochs}}
    for k in layer_list: dumpA[k] = np.stack([t.numpy() for t in spinsA[k]], 0)
    dumpB = {"meta": {**meta, "tag":"B", "init_seed":args.init_seed, "train_seed":args.train_seedB, "time":timeB, "record_epochs":rec_epochs}}
    for k in layer_list: dumpB[k] = np.stack([t.numpy() for t in spinsB[k]], 0)

    fnA = f"mlp_same_model_spinA_{input_stem}_{args.measure_data}_seed{args.init_seed}_trA{args.train_seedA}.pkl"
    fnB = f"mlp_same_model_spinB_{input_stem}_{args.measure_data}_seed{args.init_seed}_trB{args.train_seedB}.pkl"
    atomic_save_pickle(dumpA, os.path.join(outdir, fnA), logger)
    atomic_save_pickle(dumpB, os.path.join(outdir, fnB), logger)
    save_metrics_csv(os.path.join(outdir, "metrics_A.csv"), metrics_A, logger)
    save_metrics_csv(os.path.join(outdir, "metrics_B.csv"), metrics_B, logger)
    logger.info("Done.")

if __name__ == "__main__":
    main()
