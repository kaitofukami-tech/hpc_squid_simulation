#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
MLP Denoising (Diff Init)
- Based on mlp_diff_model.py
- Task: Denoising (MSE Loss, Input=Noisy, Target=Clean)
- Dataset: generated by build_denoise_datasets.py (has noisy_train, clean_train, noisy_test, clean_test)
- Train Data: noisy_train / clean_train
- Val Data: noisy_test  / clean_test (User requested using Test as Val)
- Spin Measurement:
  - --measure_data train -> Sample from noisy_train
  - --measure_data val   -> Sample from noisy_test
"""

import os, math, time, json, argparse, logging, hashlib, tempfile, shutil, gc, csv
from typing import List, Dict, Tuple
import numpy as np
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, TensorDataset

# ----------------- argparse -----------------
def build_args():
    p = argparse.ArgumentParser("MLP Denoising (diff init)")
    p.add_argument("--input", type=str, required=True,
                   help="Denoising .npz file (e.g. mnist_lambda100.npz)")
    p.add_argument("--output_dir", type=str, default="/sqfs/work/cm9029/${USER_ID}/mlp_output/denoise_diff")
    p.add_argument("--epochs", type=int, default=15)
    p.add_argument("--batch_size", type=int, default=256)
    p.add_argument("--lr", type=float, default=1e-3)

    # MLP dims
    p.add_argument("--d_model", type=int, default=256)      # D
    p.add_argument("--d_ffn", type=int, default=1024)       # Expansion dim
    p.add_argument("--num_blocks", type=int, default=10)
    p.add_argument("--dropout", type=float, default=0.1)

    # Training/Measurement
    p.add_argument("--init_seedA", type=int, default=123, help="Init seed for A")
    p.add_argument("--init_seedB", type=int, default=456, help="Init seed for B")
    p.add_argument("--train_seed", type=int, default=2025, help="Shared training shuffle seed")
    p.add_argument("--data_seed", type=int, default=4244, help="Measurement sample selection seed")
    p.add_argument("--M", type=int, default=1000, help="Number of spin measurement samples")
    p.add_argument("--record_layers", type=str, default=":post", choices=[":pre",":post"],
                   help="Record BN layers at :pre or :post")
    p.add_argument("--measure_data", type=str, default="train", choices=["train", "val"], 
                   help="Measure spins on 'train' (noisy_train) or 'val' (noisy_test)")
    p.add_argument("--no-epoch0", action="store_true", default=True, help="Skip measurement at epoch 0")
    p.add_argument("--log_level", type=str, default="INFO", choices=["DEBUG","INFO","WARNING","ERROR"])

    # Progressive recording params
    p.add_argument("--record-start", type=int, default=2)
    p.add_argument("--record-mult", type=float, default=1.5)
    p.add_argument("--record-max", type=int, default=50)
    p.add_argument("--always-include-last", action="store_true", default=True, help="Always include last epoch")

    return p.parse_args()

# ----------------- logging -----------------
def setup_logger(outdir, level="INFO"):
    os.makedirs(outdir, exist_ok=True)
    logger = logging.getLogger("MLP_Denoise_Diff")
    logger.setLevel(getattr(logging, level))
    fmt = logging.Formatter("%(asctime)s - %(levelname)s - %(message)s")
    sh = logging.StreamHandler(); sh.setFormatter(fmt)
    fh = logging.FileHandler(os.path.join(outdir, "train.log")); fh.setFormatter(fmt)
    logger.handlers.clear(); logger.addHandler(sh); logger.addHandler(fh)
    return logger

# ----------------- utils -----------------
def dev():
    return torch.device("cuda" if torch.cuda.is_available() else "cpu")

def set_seed_all(seed:int):
    torch.manual_seed(seed); np.random.seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)
        torch.backends.cudnn.deterministic = True
        torch.backends.cudnn.benchmark = False

def prep_tensor(arr):
    # arr shape: (N, 28, 28) or (N, 1, 28, 28) or (N, 784)
    # Target: (N, 1, 28, 28) floating point for model input
    t = torch.tensor(arr, dtype=torch.float32)
    if t.max() > 1.0 + 1e-6:
        t = t / 255.0
    if t.ndim == 3: # (N, H, W)
        t = t.unsqueeze(1)
    elif t.ndim == 2: # (N, D) - unlikely for image data usually stored as image, but possible
        # Reshape to image for consistency with MLP forward structure which expects (B, 1, 28, 28) and flattens
        t = t.view(t.size(0), 1, 28, 28)
    return t

def load_denoise_data(path, logger):
    logger.info(f"Loading {path} ...")
    with np.load(path) as f:
        # keys: noisy_train, clean_train, noisy_test, clean_test
        nt = f["noisy_train"]
        ct = f["clean_train"]
        nv = f["noisy_test"]
        cv = f["clean_test"]
        logger.info(f"Keys: {list(f.keys())}")
        
    nt_t = prep_tensor(nt)
    ct_t = prep_tensor(ct)
    nv_t = prep_tensor(nv)
    cv_t = prep_tensor(cv)
    
    logger.info(f"Train: noisy={tuple(nt_t.shape)}, clean={tuple(ct_t.shape)}")
    logger.info(f"Test : noisy={tuple(nv_t.shape)}, clean={tuple(cv_t.shape)}")
    
    # Dataset: (Input, Target) = (Noisy, Clean)
    train_ds = TensorDataset(nt_t, ct_t)
    val_ds   = TensorDataset(nv_t, cv_t)
    
    return train_ds, val_ds

def make_loader(dataset, bs, seed, logger, *, shuffle=True):
    g = torch.Generator()
    g.manual_seed(seed)
    dl = DataLoader(dataset, batch_size=bs, shuffle=shuffle, num_workers=2, pin_memory=True, generator=g if shuffle else None)
    if shuffle:
        logger.info(f"steps/epoch â‰ˆ {math.ceil(len(dataset)/bs)}")
    return dl

def atomic_save_pickle(obj, final_path, logger):
    os.makedirs(os.path.dirname(final_path), exist_ok=True)
    tmpdir = os.getenv("SLURM_TMPDIR", "/tmp")
    with tempfile.NamedTemporaryFile(dir=tmpdir, delete=False, suffix=".pkl") as tmp:
        import pickle
        pickle.dump(obj, tmp, protocol=pickle.HIGHEST_PROTOCOL)
        tmp.flush(); os.fsync(tmp.fileno())
        tmp_path = tmp.name
    shutil.move(tmp_path, final_path)
    sz = os.path.getsize(final_path)/(1024**2)
    logger.info(f"Saved: {final_path} ({sz:.2f} MB)")

def atomic_save_state_dict(model: nn.Module, final_path: str, logger):
    os.makedirs(os.path.dirname(final_path), exist_ok=True)
    tmpdir = os.getenv("SLURM_TMPDIR", "/tmp")
    with tempfile.NamedTemporaryFile(dir=tmpdir, delete=False, suffix=".pt") as tmp:
        torch.save(model.state_dict(), tmp)
        tmp.flush(); os.fsync(tmp.fileno())
        tmp_path = tmp.name
    shutil.move(tmp_path, final_path)
    sz = os.path.getsize(final_path)/(1024**2)
    logger.info(f"Saved checkpoint: {final_path} ({sz:.2f} MB)")

def save_metrics_csv(path, rows, logger):
    os.makedirs(os.path.dirname(path), exist_ok=True)
    with open(path, "w", newline="") as f:
        writer = csv.DictWriter(f, fieldnames=["epoch","split","loss"])
        writer.writeheader()
        for r in rows: writer.writerow(r)
    logger.info(f"Saved metrics CSV: {path}")

def model_state_hash(model):
    with torch.no_grad():
        vec = torch.cat([p.detach().float().flatten().cpu() for p in model.parameters()])
    return hashlib.sha256(vec.numpy().tobytes()).hexdigest()

# ----------------- MLP Block -----------------
class MLPBlock(nn.Module):
    def __init__(self, d_model, d_ffn, dropout=0.1):
        super().__init__()
        self.bn = nn.BatchNorm1d(d_model)
        self.fc1 = nn.Linear(d_model, d_ffn)
        self.act = nn.GELU()
        self.fc2 = nn.Linear(d_ffn, d_model)
        self.drop = nn.Dropout(dropout)

    def forward(self, x):
        residual = x
        x = self.bn(x)      # blocks.i.bn :post
        x = self.fc1(x)
        x = self.act(x)
        x = self.fc2(x)
        x = self.drop(x)
        return x + residual

# ----------------- MLP Model -----------------
class MLP(nn.Module):
    def __init__(self, input_dim=784, d_model=256, d_ffn=1024,
                 num_blocks=10, output_dim=784, dropout=0.1):
        super().__init__()
        
        self.input_proj = nn.Linear(input_dim, d_model)
        self.blocks = nn.ModuleList([
            MLPBlock(d_model, d_ffn, dropout)
            for _ in range(num_blocks)
        ])
        self.out_bn = nn.BatchNorm1d(d_model) # Final observation point
        self.output_proj = nn.Linear(d_model, output_dim) # Output projection

    def forward(self, x_img): # (B, 1, 28, 28)
        B = x_img.size(0)
        x = x_img.view(B, -1) # (B, 784)
        x = self.input_proj(x)
        for blk in self.blocks:
            x = blk(x)
        x = self.out_bn(x)
        return self.output_proj(x)

# ----------------- Init -----------------
def init_random_normal_and_bias_const(model: nn.Module, *, mean=0.0, std=1.0, bias_const=0.1):
    for m in model.modules():
        if isinstance(m, (nn.Linear, nn.Conv1d)):
            if m.weight is not None:
                nn.init.normal_(m.weight, mean=mean, std=std)
            if m.bias is not None:
                nn.init.constant_(m.bias, bias_const)

# ----------------- spin recording -----------------
@torch.no_grad()
def measure_spins(model: nn.Module, layer_names: List[str], X_meas: torch.Tensor, batch: int, logger):
    model.eval()
    store = {ln: [] for ln in layer_names}
    
    # Parse layers
    name_map = {}
    for ln in layer_names:
        base = ln.replace(':pre','').replace(':post','')
        is_pre = ln.endswith(':pre')
        name_map.setdefault(base, []).append((ln, is_pre))

    handles = []
    for n, m in model.named_modules():
        if n in name_map:
            for out_key, is_pre in name_map[n]:
                if is_pre:
                    def _pre_hook_factory(key):
                        def _pre(_m, inputs):
                            store[key].append(inputs[0].detach().to("cpu", dtype=torch.float16))
                        return _pre
                    handles.append(m.register_forward_pre_hook(_pre_hook_factory(out_key)))
                else:
                    def _hook_factory(key):
                        def _hook(_m, _in, out):
                            store[key].append(out.detach().to("cpu", dtype=torch.float16))
                        return _hook
                    handles.append(m.register_forward_hook(_hook_factory(out_key)))

    dl = DataLoader(TensorDataset(X_meas), batch_size=batch, shuffle=False, num_workers=2, pin_memory=True)
    d = dev()
    
    # Forward pass
    for (xb,) in dl:
        _ = model(xb.to(d, non_blocking=True))
        
    for h in handles: h.remove()

    for k in store.keys():
        store[k] = torch.cat(store[k], dim=0)
        logger.info(f"[spin] {k}: {tuple(store[k].shape)}")
    if torch.cuda.is_available(): torch.cuda.empty_cache()
    return store

# ----------------- Progressive recording scheduler -----------------
def build_epochs_1_3_then_progressive(total_epochs: int, start: int, mult: float, max_interval: int, include_last: bool) -> List[int]:
    fixed = [e for e in (1, 3) if 1 <= e <= total_epochs]
    epochs = list(sorted(set(fixed)))
    cur = 3 if 3 <= total_epochs else (1 if 1 <= total_epochs else 0)
    interval = max(1, start)
    i = 0
    while True:
        cur = cur + interval
        if cur > total_epochs: break
        if cur not in epochs: epochs.append(cur)
        interval = min(max_interval, max(1, int(round(interval * mult))))
        i += 1
        if i > 10000: break
    if include_last and total_epochs >= 1 and total_epochs not in epochs:
        epochs.append(total_epochs)
    return sorted(set([e for e in epochs if 1 <= e <= total_epochs]))

# ----------------- train / eval -----------------
def train_one_epoch(model, loader, opt, loss_fn, logger, tag):
    model.train(); d = dev()
    total_loss, n = 0.0, 0
    for xb, yb in loader: # xb=noisy, yb=clean
        xb, yb = xb.to(d, non_blocking=True), yb.to(d, non_blocking=True)
        # Flatten target
        yb_flat = yb.view(yb.size(0), -1) 
        
        opt.zero_grad(set_to_none=True)
        out = model(xb) # (B, 784)
        loss = loss_fn(out, yb_flat)
        loss.backward()
        opt.step()
        
        total_loss += float(loss) * xb.size(0)
        n += xb.size(0)
        del xb, yb, yb_flat, out, loss
        
    avg_loss = total_loss / max(n, 1)
    logger.info(f"[{tag}] train_loss={avg_loss:.6f}")
    return avg_loss

@torch.no_grad()
def eval_full(model, loader, loss_fn):
    model.eval(); d = dev()
    total_loss, n = 0.0, 0
    for xb, yb in loader:
        xb, yb = xb.to(d, non_blocking=True), yb.to(d, non_blocking=True)
        yb_flat = yb.view(yb.size(0), -1)
        out = model(xb)
        loss = loss_fn(out, yb_flat)
        total_loss += float(loss) * xb.size(0)
        n += xb.size(0)
    return total_loss / max(n, 1)

# ----------------- main -----------------
def main():
    args = build_args()
    ts = time.strftime("%Y%m%d-%H%M%S")
    # Base output name based on input filename stem (e.g. mnist_lambda100)
    input_stem = os.path.splitext(os.path.basename(args.input))[0]
    run_name = f"run_{input_stem}_{args.measure_data}_{ts}"
    outdir = os.path.join(args.output_dir, run_name)
    logger = setup_logger(outdir, args.log_level)
    
    logger.info(f"Args: {json.dumps(vars(args), ensure_ascii=False)}")
    ckpt_root = os.path.join(args.output_dir, "checkpoints", run_name)
    ckpt_dir_A = os.path.join(ckpt_root, "A")
    ckpt_dir_B = os.path.join(ckpt_root, "B")

    # GPU
    if torch.cuda.is_available():
        logger.info(f"GPU: {torch.cuda.get_device_name(0)}")

    # Load Denoising Data (Pre-split train/test in NPZ)
    train_ds, val_ds = load_denoise_data(args.input, logger)
    
    # Measurement Selection
    if args.measure_data == "train":
        # train_ds has (noisy, clean). We need noisy inputs for spin measurement.
        # TensorDataset[i] returns (noisy, clean). 
        # But we need indices to sample. TensorDataset wraps tensors.
        # We can directly access .tensors[0] (noisy)
        source_data = train_ds.tensors[0] # Noisy inputs
        logger.info(f"Measure Target: TRAIN (N={len(source_data)})")
    else:
        source_data = val_ds.tensors[0]   # Noisy inputs
        logger.info(f"Measure Target: VAL/TEST (N={len(source_data)})")
        
    rng = np.random.RandomState(args.data_seed)
    N_total = len(source_data)
    if N_total < args.M:
        idx_meas = np.arange(N_total)
        logger.warning(f"Pool {N_total} < M={args.M}, using all.")
    else:
        idx_meas = rng.choice(N_total, size=args.M, replace=False)
        
    X_meas = source_data[idx_meas].clone() # Copy
    logger.info(f"X_meas shape: {tuple(X_meas.shape)}")

    # Loaders
    loaderA = make_loader(train_ds, args.batch_size, seed=args.train_seed, logger=logger, shuffle=True)
    loaderB = make_loader(train_ds, args.batch_size, seed=args.train_seed, logger=logger, shuffle=True)
    # Eval loaders (no shuffle)
    train_eval_loader = make_loader(train_ds, args.batch_size, seed=0, logger=logger, shuffle=False)
    val_loader        = make_loader(val_ds,   args.batch_size, seed=0, logger=logger, shuffle=False)

    # Layers
    layer_list = [f"blocks.{i}.bn{args.record_layers}" for i in range(args.num_blocks)]
    logger.info(f"Layers: {layer_list}")
    
    rec_epochs = build_epochs_1_3_then_progressive(args.epochs, args.record_start, args.record_mult, args.record_max, args.always_include_last)
    logger.info(f"Epochs: {rec_epochs}")

    loss_fn = nn.MSELoss()
    d = dev()
    
    # ====== Models ======
    set_seed_all(args.init_seedA)
    modelA = MLP(d_model=args.d_model, d_ffn=args.d_ffn, num_blocks=args.num_blocks, 
                 output_dim=784, dropout=args.dropout).to(d)
    init_random_normal_and_bias_const(modelA)
    hashA = model_state_hash(modelA)
    logger.info(f"HashA: {hashA[:16]}")
    
    set_seed_all(args.init_seedB)
    modelB = MLP(d_model=args.d_model, d_ffn=args.d_ffn, num_blocks=args.num_blocks, 
                 output_dim=784, dropout=args.dropout).to(d)
    init_random_normal_and_bias_const(modelB)
    hashB = model_state_hash(modelB)
    logger.info(f"HashB: {hashB[:16]}")
    
    spinsA = {ln: [] for ln in layer_list}; timeA = []
    spinsB = {ln: [] for ln in layer_list}; timeB = []
    metrics_A = []; metrics_B = []
    ckpt_A = []; ckpt_B = []

    # Epoch 0
    if not args.no_epoch0:
        s = measure_spins(modelA, layer_list, X_meas, min(256, len(X_meas)), logger)
        for k in layer_list: spinsA[k].append(s[k])
        timeA.append(0)
        s = measure_spins(modelB, layer_list, X_meas, min(256, len(X_meas)), logger)
        for k in layer_list: spinsB[k].append(s[k])
        timeB.append(0)
        
        pa = os.path.join(ckpt_dir_A, "epoch0000.pt")
        atomic_save_state_dict(modelA, pa, logger)
        ckpt_A.append({"epoch":0, "path":pa})
        pb = os.path.join(ckpt_dir_B, "epoch0000.pt")
        atomic_save_state_dict(modelB, pb, logger)
        ckpt_B.append({"epoch":0, "path":pb})
    
    optA = torch.optim.Adam(modelA.parameters(), lr=args.lr)
    optB = torch.optim.Adam(modelB.parameters(), lr=args.lr)
    
    for ep in range(1, args.epochs+1):
        train_one_epoch(modelA, loaderA, optA, loss_fn, logger, f"A/ep{ep}")
        train_one_epoch(modelB, loaderB, optB, loss_fn, logger, f"B/ep{ep}")
        
        if ep in rec_epochs:
            sA = measure_spins(modelA, layer_list, X_meas, min(256, len(X_meas)), logger)
            for k in layer_list: spinsA[k].append(sA[k])
            timeA.append(ep)
            sB = measure_spins(modelB, layer_list, X_meas, min(256, len(X_meas)), logger)
            for k in layer_list: spinsB[k].append(sB[k])
            timeB.append(ep)
            
            la_tr = eval_full(modelA, train_eval_loader, loss_fn)
            la_va = eval_full(modelA, val_loader, loss_fn)
            metrics_A.extend([
                {"epoch": ep, "split": "train", "loss": f"{la_tr:.6f}"},
                {"epoch": ep, "split": "val",   "loss": f"{la_va:.6f}"},
            ])
            lb_tr = eval_full(modelB, train_eval_loader, loss_fn)
            lb_va = eval_full(modelB, val_loader, loss_fn)
            metrics_B.extend([
                {"epoch": ep, "split": "train", "loss": f"{lb_tr:.6f}"},
                {"epoch": ep, "split": "val",   "loss": f"{lb_va:.6f}"},
            ])
            logger.info(f"Eval[{ep}] A: tr={la_tr:.5f} val={la_va:.5f} | B: tr={lb_tr:.5f} val={lb_va:.5f}")
            
            pa = os.path.join(ckpt_dir_A, f"epoch{ep:04d}.pt")
            atomic_save_state_dict(modelA, pa, logger)
            ckpt_A.append({"epoch":ep, "path":pa})
            pb = os.path.join(ckpt_dir_B, f"epoch{ep:04d}.pt")
            atomic_save_state_dict(modelB, pb, logger)
            ckpt_B.append({"epoch":ep, "path":pb})
            gc.collect()

    # Save Results
    meta = dict(
        data_name=input_stem,
        d_model=args.d_model, d_ffn=args.d_ffn, num_blocks=args.num_blocks, 
        dropout=args.dropout, record_layers=args.record_layers, M=args.M, 
        measure_data=args.measure_data, arch="MLP_Denoise"
    )
    
    dumpA = {"meta": {**meta, "tag":"A", "init_seed":args.init_seedA, "train_seed":args.train_seed, 
                      "time":timeA, "record_epochs":rec_epochs, "checkpoints":ckpt_A}}
    for k in layer_list: dumpA[k] = np.stack([t.numpy() for t in spinsA[k]], 0)
    
    dumpB = {"meta": {**meta, "tag":"B", "init_seed":args.init_seedB, "train_seed":args.train_seed, 
                      "time":timeB, "record_epochs":rec_epochs, "checkpoints":ckpt_B}}
    for k in layer_list: dumpB[k] = np.stack([t.numpy() for t in spinsB[k]], 0)

    fnA = f"mlp_denoise_spinA_{input_stem}_{args.measure_data}_seedA{args.init_seedA}.pkl"
    fnB = f"mlp_denoise_spinB_{input_stem}_{args.measure_data}_seedB{args.init_seedB}.pkl"
    
    atomic_save_pickle(dumpA, os.path.join(outdir, fnA), logger)
    atomic_save_pickle(dumpB, os.path.join(outdir, fnB), logger)
    
    save_metrics_csv(os.path.join(outdir, "metrics_A.csv"), metrics_A, logger)
    save_metrics_csv(os.path.join(outdir, "metrics_B.csv"), metrics_B, logger)
    
    logger.info("Done.")

if __name__ == "__main__":
    main()
